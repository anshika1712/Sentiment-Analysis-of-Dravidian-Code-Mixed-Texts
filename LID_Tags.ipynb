{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHZOpzGh7h8/9FZXVjK+yW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshika1712/Sentiment-Analysis-of-Dravidian-Code-Mixed-Texts/blob/main/LID_Tags.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhqFecqG8wCK"
      },
      "outputs": [],
      "source": [
        "#Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the training dataset\n",
        "train_data=pd.read_csv('/content/Kan_Train_Dataset_1.csv')"
      ],
      "metadata": {
        "id": "9K69PTsMidKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the testing dataset\n",
        "test_data=pd.read_csv('/content/Kan_Test_Dataset_1.csv')"
      ],
      "metadata": {
        "id": "P5ug8CDMigDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the validation dataset\n",
        "val_data=pd.read_csv('/content/Kan_Dev_Dataset_1.csv')"
      ],
      "metadata": {
        "id": "nXXDm5zCikFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['tokenized_text']=train_data['tokenized_text'].apply(eval)\n",
        "test_data['tokenized_text']=test_data['tokenized_text'].apply(eval)\n",
        "val_data['tokenized_text']=val_data['tokenized_text'].apply(eval)"
      ],
      "metadata": {
        "id": "LqLjTCH2ilt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "id": "EVC4h9EiinwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Looking at top five values\n",
        "test_data.head()"
      ],
      "metadata": {
        "id": "nHLM_m7Pirze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data.head()"
      ],
      "metadata": {
        "id": "6sgrmzBditdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the counts of different tags\n",
        "train_data['category'].value_counts()"
      ],
      "metadata": {
        "id": "mpWypjw3ivOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data['category'].value_counts()"
      ],
      "metadata": {
        "id": "FkNlVUgjizJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the count of comments\n",
        "test_data['text'].count()"
      ],
      "metadata": {
        "id": "p-0vWKKUi2L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install googletrans==3.1.0a0"
      ],
      "metadata": {
        "id": "3tyOz9VKi4xI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "#Function for LID\n",
        "def lid_word(text):\n",
        "  translator = Translator()\n",
        "  l=[]\n",
        "  c=0\n",
        "  langs=translator.detect(text)\n",
        "  for lang in langs:\n",
        "    l.append([text[c],lang.lang])\n",
        "    c+=1\n",
        "  return(l)\n"
      ],
      "metadata": {
        "id": "Xl9BHM8ejAK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from tqdm.auto import tqdm\n",
        "data['LID list']=[lid_word(t) for t in tqdm(data['tokenized_text'].values)]\n",
        "data.head()"
      ],
      "metadata": {
        "id": "k5c9a0LvjCFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv('Tamil_LID_Test2022.csv')"
      ],
      "metadata": {
        "id": "7BWS151ijOX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the preprocessed training dataset as a csv file\n",
        "sample_data.to_csv(r'sample_data(1).csv', index=False)"
      ],
      "metadata": {
        "id": "FLxKAZuwjQY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(figsize = (20,5))\n",
        "ax.bar(df['Language'].value_counts().index,\n",
        "        df['Language'].value_counts().values)\n",
        "ax.set_ylabel(\"Frequency\", size = 12, )\n",
        "ax.set_title(\"Different languages\", size = 14)\n",
        "\n",
        "#plt.tick_params(axis='x', which='major', labelsize=__)"
      ],
      "metadata": {
        "id": "JpW_C4F0jUQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k8dqf2BAj8Pu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}